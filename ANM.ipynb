{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLU4181zjG/CeTT7EgIDQv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SoftwereENKKz/Lab1_633020040-5/blob/main/ANM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3ZKdHKQgdbKE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b784dda-c8dc-489e-b014-365b37419250"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 🚀 v7.0-132-ga82132c Python-3.9.16 torch-1.13.1+cu116 CPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 25.7/107.7 GB disk)\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "%cd /content/yolov5\n",
        "%pip install -qr requirements.txt  # install\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFBgN-z9OXV8",
        "outputId": "5dbd952b-b772-4221-b845-6e34f1e5732d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q wandb\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "ttyRm-Y07QIH",
        "outputId": "8610d9ea-79ab-4ef0-f155-8877a65d09f7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/2.0 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 KB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img 416 --epochs 20 --data anm.yaml --weights yolov5s.pt "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TaOhCeX7VT2",
        "outputId": "186445b0-9d1f-4351-e21c-39eed453d2a3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ⚠️ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myosapat-tbp\u001b[0m (\u001b[33mproject-anm\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=anm.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=20, batch_size=16, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v7.0-132-ga82132c Python-3.9.16 torch-1.13.1+cu116 CPU\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "2023-03-31 18:09:59.019595: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-31 18:10:00.500597: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.14.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/yolov5/wandb/run-20230331_181002-9850zvli\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mflowing-dawn-15\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/project-anm/YOLOv5\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/project-anm/YOLOv5/runs/9850zvli\u001b[0m\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
            "100% 14.1M/14.1M [00:00<00:00, 63.4MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=5\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     26970  models.yolo.Detect                      [5, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7033114 parameters, 7033114 gradients, 16.0 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Project_ANM/WildLife_Dataset/train/labels... 752 images, 0 backgrounds, 0 corrupt: 100% 752/752 [04:40<00:00,  2.68it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/Project_ANM/WildLife_Dataset/train/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Project_ANM/WildLife_Dataset/train/labels.cache... 752 images, 0 backgrounds, 0 corrupt: 100% 752/752 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.59 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to runs/train/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/19         0G    0.09304    0.03406    0.03702         48        416: 100% 47/47 [09:24<00:00, 12.00s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  12% 3/24 [00:29<03:28,  9.91s/it]WARNING ⚠️ NMS time limit 2.100s exceeded\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [03:54<00:00,  9.77s/it]\n",
            "                   all        752       1497      0.714      0.222      0.185     0.0612\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/19         0G    0.06952     0.0328    0.01349         74        416: 100% 47/47 [09:17<00:00, 11.86s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [03:17<00:00,  8.22s/it]\n",
            "                   all        752       1497      0.705      0.249      0.217     0.0927\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/19         0G    0.06647    0.03135   0.009519         68        416: 100% 47/47 [09:16<00:00, 11.85s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [03:08<00:00,  7.86s/it]\n",
            "                   all        752       1497      0.743      0.256      0.349      0.146\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/19         0G    0.06092    0.02969   0.007396         49        416: 100% 47/47 [09:11<00:00, 11.73s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [03:06<00:00,  7.79s/it]\n",
            "                   all        752       1497      0.498      0.566      0.495      0.209\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/19         0G      0.057    0.02955   0.005879         67        416: 100% 47/47 [09:09<00:00, 11.70s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [03:08<00:00,  7.84s/it]\n",
            "                   all        752       1497      0.429      0.533      0.412      0.197\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/19         0G    0.05186     0.0293   0.005311         63        416: 100% 47/47 [09:01<00:00, 11.52s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [03:03<00:00,  7.66s/it]\n",
            "                   all        752       1497      0.664      0.737      0.725      0.403\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/19         0G    0.04848    0.02893   0.004503         56        416: 100% 47/47 [09:06<00:00, 11.63s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [03:02<00:00,  7.61s/it]\n",
            "                   all        752       1497      0.691      0.704      0.712      0.415\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/19         0G    0.04662    0.02854   0.003971         84        416: 100% 47/47 [09:21<00:00, 11.95s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [03:18<00:00,  8.27s/it]\n",
            "                   all        752       1497      0.797      0.753      0.806      0.474\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/19         0G    0.04398    0.02832   0.003557         64        416: 100% 47/47 [09:07<00:00, 11.66s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [02:59<00:00,  7.47s/it]\n",
            "                   all        752       1497      0.847      0.723      0.823      0.461\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/19         0G    0.04296    0.02642   0.003881         53        416: 100% 47/47 [09:01<00:00, 11.52s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [03:05<00:00,  7.73s/it]\n",
            "                   all        752       1497      0.866      0.786      0.843      0.508\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/19         0G    0.04204    0.02669   0.003325         75        416: 100% 47/47 [09:02<00:00, 11.55s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [03:02<00:00,  7.59s/it]\n",
            "                   all        752       1497       0.83      0.795       0.84      0.527\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/19         0G    0.03955    0.02612   0.003206         54        416: 100% 47/47 [09:04<00:00, 11.58s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [03:07<00:00,  7.83s/it]\n",
            "                   all        752       1497      0.852      0.793      0.849      0.493\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/19         0G    0.03886     0.0264     0.0027         77        416: 100% 47/47 [09:09<00:00, 11.70s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [03:18<00:00,  8.25s/it]\n",
            "                   all        752       1497      0.879      0.824      0.878      0.563\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/19         0G    0.03778    0.02696   0.002875         72        416: 100% 47/47 [09:03<00:00, 11.57s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [02:58<00:00,  7.42s/it]\n",
            "                   all        752       1497      0.913      0.842      0.898      0.601\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/19         0G    0.03654     0.0262   0.002631         72        416: 100% 47/47 [09:10<00:00, 11.71s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [03:03<00:00,  7.64s/it]\n",
            "                   all        752       1497      0.909      0.848      0.897      0.619\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/19         0G    0.03548     0.0245   0.002309         66        416: 100% 47/47 [09:11<00:00, 11.74s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [03:00<00:00,  7.51s/it]\n",
            "                   all        752       1497      0.906      0.864      0.902      0.609\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/19         0G    0.03372    0.02401   0.002361         70        416: 100% 47/47 [09:07<00:00, 11.66s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [03:03<00:00,  7.64s/it]\n",
            "                   all        752       1497      0.919      0.858      0.908      0.637\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/19         0G     0.0332      0.025   0.002484         65        416: 100% 47/47 [09:11<00:00, 11.73s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [03:33<00:00,  8.91s/it]\n",
            "                   all        752       1497      0.906      0.865      0.909      0.649\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/19         0G     0.0327    0.02447    0.00209         60        416: 100% 47/47 [09:18<00:00, 11.87s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [03:06<00:00,  7.78s/it]\n",
            "                   all        752       1497      0.925       0.86      0.914      0.645\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/19         0G     0.0323    0.02472   0.002277         64        416: 100% 47/47 [09:22<00:00, 11.98s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [03:19<00:00,  8.31s/it]\n",
            "                   all        752       1497      0.926      0.874      0.916      0.663\n",
            "\n",
            "20 epochs completed in 4.126 hours.\n",
            "Optimizer stripped from runs/train/exp/weights/last.pt, 14.3MB\n",
            "Optimizer stripped from runs/train/exp/weights/best.pt, 14.3MB\n",
            "\n",
            "Validating runs/train/exp/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7023610 parameters, 0 gradients, 15.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 24/24 [03:21<00:00,  8.41s/it]\n",
            "                   all        752       1497      0.926      0.874      0.916      0.664\n",
            "                  bull        752       1351      0.917      0.836      0.909      0.646\n",
            "                  deer        752        146      0.936      0.911      0.924      0.681\n",
            "Results saved to \u001b[1mruns/train/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▃▄▃▆▆▇▇▇▇▇█████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▂▃▃▅▅▆▆▆▆▆▇▇▇▇█████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▅▅▅▂▁▄▅▆▇▇▇▇▇████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▅▄▇▆▇▆▇▇▇▇████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▅▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss █▇▆▅▅▅▄▄▄▃▃▂▃▃▃▁▁▂▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss █▇▆▅▅▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss █▅▄▃▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss █▇▅▅▄▄▃▃▃▃▃▃▂▂▂▂▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 █▅▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▃▆███▇▇▆▆▅▅▅▄▄▃▃▂▂▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▃▆███▇▇▆▆▅▅▅▄▄▃▃▂▂▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 19\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.91644\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.66347\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.92591\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.87369\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.91634\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.6637\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.92643\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.87362\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.0323\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.00228\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02472\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.02574\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.00094\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01076\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00109\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00109\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00109\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mflowing-dawn-15\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/project-anm/YOLOv5/runs/9850zvli\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 17 media file(s), 3 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230331_181002-9850zvli/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ⚠️ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights runs/train/exp5/weights/best.pt  --source /content/drive/MyDrive/Project_ANM/ANM_TEST/test1/images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imos7GiNCrGy",
        "outputId": "8855fee4-b987-4989-ff95-02136c69b283"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/exp5/weights/best.pt'], source=/content/drive/MyDrive/Project_ANM/ANM_TEST/test1/images, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 🚀 v7.0-132-ga82132c Python-3.9.16 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n",
            "image 1/33 /content/drive/MyDrive/Project_ANM/ANM_TEST/test1/images/AdobeStock_468595893_Preview.jpeg: 448x640 3 monkeys, 13.9ms\n",
            "image 2/33 /content/drive/MyDrive/Project_ANM/ANM_TEST/test1/images/AdobeStock_483867012_Preview.jpeg: 448x640 8 monkeys, 10.0ms\n",
            "image 3/33 /content/drive/MyDrive/Project_ANM/ANM_TEST/test1/images/AdobeStock_575849440_Preview.jpeg: 544x640 1 monkey, 13.4ms\n",
            "image 4/33 /content/drive/MyDrive/Project_ANM/ANM_TEST/test1/images/e83cb00a2ef1053ed1584d05fb1d4e9fe777ead218ac104497f5c978a4efbcb0_640_jpg.rf.c544658257d7853ae7da348a54f05f99.jpg: 640x640 (no detections), 12.9ms\n",
            "image 5/33 /content/drive/MyDrive/Project_ANM/ANM_TEST/test1/images/e83db30d2cfc003ed1584d05fb1d4e9fe777ead218ac104497f5c978a4efb4bb_640_jpg.rf.1cd9ddcffc5f0761d43ab78013078a75.jpg: 640x640 5 monkeys, 12.8ms\n",
            "image 6/33 /content/drive/MyDrive/Project_ANM/ANM_TEST/test1/images/e83db40c28f7003ed1584d05fb1d4e9fe777ead218ac104497f5c978a4efbcb0_640_jpg.rf.da8baf4f0e1df07f0f06fd5807800e17.jpg: 640x640 (no detections), 12.8ms\n",
            "image 7/33 /content/drive/MyDrive/Project_ANM/ANM_TEST/test1/images/e83db70f21fc033ed1584d05fb1d4e9fe777ead218ac104497f5c978a4efbcb0_640_jpg.rf.f040dcfca395429aea631088c2038403.jpg: 640x640 1 monkey, 12.8ms\n",
            "image 8/33 /content/drive/MyDrive/Project_ANM/ANM_TEST/test1/images/ea35b70f2df6073ed1584d05fb1d4e9fe777ead218ac104497f5c978a4efb4bb_640_jpg.rf.71b15247e5ef667762ca900a81e603e7.jpg: 640x640 6 monkeys, 12.8ms\n",
            "image 9/33 /content/drive/MyDrive/Project_ANM/ANM_TEST/test1/images/ea35b80c2df2073ed1584d05fb1d4e9fe777ead218ac104497f5c978a4efbcb0_640_jpg.rf.d1afdf5f431e52ac92548e1cee8276c2.jpg: 640x640 4 monkeys, 12.8ms\n",
            "image 10/33 /content/drive/MyDrive/Project_ANM/ANM_TEST/test1/images/ea36b0082bf2063ed1584d05fb1d4e9fe777ead218ac104497f5c978a4efb4bb_640_jpg.rf.2fb2d6091aa2cd1160a5fdf65e8531fa.jpg: 640x640 1 monkey, 12.7ms\n",
            "image 11/33 /content/drive/MyDrive/Project_ANM/ANM_TEST/test1/images/ea36b10928f5023ed1584d05fb1d4e9fe777ead218ac104497f5c978a4efb4bb_640_jpg.rf.02235691227d383e549a7d0af9f5429a.jpg: 640x640 1 monkey, 12.8ms\n",
            "image 12/33 /content/drive/MyDrive/Project_ANM/ANM_TEST/test1/images/ea36b10c2cfd043ed1584d05fb1d4e9fe777ead218ac104497f5c978a4efbcb0_640_jpg.rf.f258de759b6707c635ad930c4e6a7867.jpg: 640x640 2 monkeys, 12.8ms\n",
            "image 13/33 /content/drive/MyDrive/Project_ANM/ANM_TEST/test1/images/ea36b30a21f3043ed1584d05fb1d4e9fe777ead218ac104497f5c978a4efb4bb_640_jpg.rf.eb842ebfc8018ad6a7963751b7d0dd80.jpg: 640x640 4 monkeys, 12.8ms\n",
            "image 14/33 /content/drive/MyDrive/Project_ANM/ANM_TEST/test1/images/ea37b10821f7003ed1584d05fb1d4e9fe777ead218ac104497f5c978a4efbcb0_640_jpg.rf.4f910daf03bd541f05d202b3332e5f45.jpg: 640x640 (no detections), 14.5ms\n",
            "image 15/33 /content/drive/MyDrive/Project_ANM/ANM_TEST/test1/images/ea37b50b2dfc013ed1584d05fb1d4e9fe777ead218ac104497f5c978a4efbcb0_640_jpg.rf.d9ab8c41cf64183f001bb6be49ededf9.jpg: 640x640 (no detections), 16.3ms\n",
            "image 16/33 /content/drive/MyDrive/Project_ANM/ANM_TEST/test1/images/eb30b50a2dfc043ed1584d05fb1d4e9fe777ead218ac104497f5c978a4eebdbd_640_jpg.rf.aaf2dc1e8f46c712f118957c955848e5.jpg: 640x640 3 monkeys, 12.8ms\n",
            "image 17/33 /content/drive/MyDrive/Project_ANM/ANM_TEST/test1/images/eb30b90d29fc043ed1584d05fb1d4e9fe777ead218ac104497f5c978a4efbcb0_640_jpg.rf.4fe6c43104aed9a91ec8353e903df5ff.jpg: 640x640 2 monkeys, 15.2ms\n",
            "image 18/33 /content/drive/MyDrive/Project_ANM/ANM_TEST/test1/images/eb33b10f2cf3093ed1584d05fb1d4e9fe777ead218ac104497f5c978a4eebdbd_640_jpg.rf.dc60c8533b523131a2e5505a1befaf99.jpg: 640x640 7 monkeys, 12.9ms\n",
            "image 19/33 /content/drive/MyDrive/Project_ANM/ANM_TEST/test1/images/eb33b2092df4023ed1584d05fb1d4e9fe777ead218ac104497f5c978a4eebdbd_640_jpg.rf.72a026453aec5a162dfea05c33049c56.jpg: 640x640 (no detections), 12.8ms\n",
            "image 20/33 /content/drive/MyDrive/Project_ANM/ANM_TEST/test1/images/eb33b20d2dfc043ed1584d05fb1d4e9fe777ead218ac104497f5c978a4eebdbd_640_jpg.rf.83d951a51993f18543146901d2d78d9c.jpg: 640x640 (no detections), 12.7ms\n",
            "image 21/33 /content/drive/MyDrive/Project_ANM/ANM_TEST/test1/images/eb33b5062df2003ed1584d05fb1d4e9fe777ead218ac104497f5c978a4eebdbd_640_jpg.rf.c45254e9647ecb369ba49883464d62b7.jpg: 640x640 5 monkeys, 12.7ms\n",
            "image 22/33 /content/drive/MyDrive/Project_ANM/ANM_TEST/test1/images/eb33b7072ef3043ed1584d05fb1d4e9fe777ead218ac104497f5c978a4efbcb0_640_jpg.rf.e44cdfcc6ec08cfb93c38471edcde419.jpg: 640x640 18 monkeys, 12.8ms\n",
            "image 23/33 /content/drive/MyDrive/Project_ANM/ANM_TEST/test1/images/eb34b00b2cf1003ed1584d05fb1d4e9fe777ead218ac104497f5c978a4eebdbd_640_jpg.rf.4ef2688def61196e54a542d23947969e.jpg: 640x640 (no detections), 12.8ms\n",
            "image 24/33 /content/drive/MyDrive/Project_ANM/ANM_TEST/test1/images/eb34b10721f3013ed1584d05fb1d4e9fe777ead218ac104497f5c978a4eebdbd_640_jpg.rf.3688957ad186d880097d248186443ca6.jpg: 640x640 2 monkeys, 12.8ms\n",
            "image 25/33 /content/drive/MyDrive/Project_ANM/ANM_TEST/test1/images/eb34b10721f3053ed1584d05fb1d4e9fe777ead218ac104497f5c978a4eebdbd_640_jpg.rf.8894d80b0c473a1a6d0a5d652ead57dd.jpg: 640x640 6 monkeys, 12.8ms\n",
            "image 26/33 /content/drive/MyDrive/Project_ANM/ANM_TEST/test1/images/eb37b50d21fc093ed1584d05fb1d4e9fe777ead218ac104497f5c978a4eebdbd_640_jpg.rf.7d6687cca0427ca7fc8d3511f6e37410.jpg: 640x640 5 monkeys, 12.8ms\n",
            "image 27/33 /content/drive/MyDrive/Project_ANM/ANM_TEST/test1/images/eb3cb10e28f7073ed1584d05fb1d4e9fe777ead218ac104497f5c978a4eebdbd_640_jpg.rf.3bfd7407bef06e9f9988c1f3aba6f0ed.jpg: 640x640 6 monkeys, 12.8ms\n",
            "image 28/33 /content/drive/MyDrive/Project_ANM/ANM_TEST/test1/images/eb3db00e2cfd033ed1584d05fb1d4e9fe777ead218ac104497f5c978a4efbcb0_640_jpg.rf.f3ecdfb59d143051d5ba41db306ae77d.jpg: 640x640 20 monkeys, 12.8ms\n",
            "image 29/33 /content/drive/MyDrive/Project_ANM/ANM_TEST/test1/images/eb3db80b2cfc033ed1584d05fb1d4e9fe777ead218ac104497f5c978a4efb4bb_640_jpg.rf.78db398d8cc04df08ded12039f95872e.jpg: 640x640 14 monkeys, 12.8ms\n",
            "image 30/33 /content/drive/MyDrive/Project_ANM/ANM_TEST/test1/images/elephant-symbolism6.jpg: 448x640 5 monkeys, 10.1ms\n",
            "image 31/33 /content/drive/MyDrive/Project_ANM/ANM_TEST/test1/images/images (1).jpg: 384x640 4 monkeys, 14.9ms\n",
            "image 32/33 /content/drive/MyDrive/Project_ANM/ANM_TEST/test1/images/images.jpg: 640x576 4 monkeys, 17.1ms\n",
            "image 33/33 /content/drive/MyDrive/Project_ANM/ANM_TEST/test1/images/wild-mother-african-elephant-and-her-baby-961044554-bfd4942ccd044e8f995e825104c7570b.jpg: 448x640 4 monkeys, 13.5ms\n",
            "Speed: 0.6ms pre-process, 13.1ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/exp3\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}